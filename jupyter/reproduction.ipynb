{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our paper, we design four RQs to evaluate Upbeat:\n",
    "* RQ1: How effectively Upbeat is on detecting boundary bugs in Q# libraries?\n",
    "* RQ2: How does Upbeat compare with prior methods and baselines on bug detection?\n",
    "* RQ3: How do individual components of Upbeat contribute to its overall performance?\n",
    "* RQ4: How effective is Upbeat in extracting constraints from Q# libraries and API documents?\n",
    "\n",
    "Please run the following cells to view our experiment results.\n",
    "\n",
    "### Results for RQ1\n",
    "\n",
    "During our experiment period, Upbeat has uncovered 16 implementation bugs and 4 API document errors. To review all the bugs detected by Upbeat during this period, please run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_tables_from_md(md_file):\n",
    "    with open(md_file, 'r', encoding='utf-8') as file:\n",
    "        md_content = file.read()\n",
    "\n",
    "    # 使用正则表达式匹配Markdown中的表格\n",
    "    table_pattern = r'\\|.*\\|[\\s\\S]*?\\n(?=\\n|\\Z)'\n",
    "    tables = re.findall(table_pattern, md_content)\n",
    "\n",
    "    return tables\n",
    "\n",
    "def main():\n",
    "    md_file = '../data/experiment/BugList.md'  # 替换为你的Markdown文件路径\n",
    "    tables = extract_tables_from_md(md_file)\n",
    "\n",
    "    for table in tables:\n",
    "        print(table)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for RQ2\n",
    "\n",
    "Upbeat outperforms the competing baselines by providing better code coverage and identifying more potential bugs with the same test time. Execute the following two cells to observe the coverage and anomaly results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline, interp1d\n",
    "\n",
    "from Fuzzing.calculate_code_coverage import calculate_coverage\n",
    "\n",
    "color_list = ['#9EB3C2', '#AFCAD0', '#C0E0DE', '#8BC3D9', '#6EACC7', '#468FAF', '#297596', '#014F86', '#013A63']\n",
    "tool_list = ['qsharpfuzz', 'quito', 'qsharpcheck', 'upbeat-m', 'muskit', 'qdiff', 'morphq', 'upbeat-r', 'upbeat']\n",
    "# marker_list = [',', 'o', '^', 'v', 'D', '<', '>', 'p', '*']\n",
    "\n",
    "def draw_one_line(y, label, color):\n",
    "    x = range(0, 25)\n",
    "    x_list = np.linspace(0, 24, 50)\n",
    "    f = interp1d(x, y, kind='linear')\n",
    "    y_list = f(x_list)\n",
    "    plt.plot(x_list, y_list, label=label, color=color)\n",
    "\n",
    "input_folder = \"../data/experiment/cov-result-origin/\"\n",
    "output_folder = \"../data/experiment/cov-result-calculated/\"\n",
    "# for input_file in os.listdir(input_folder):\n",
    "#     print(\"processing \"+input_file)\n",
    "#     calculate_coverage(input_folder+input_file, output_folder+input_file)\n",
    "line_cov_list, block_cov_list = [], []\n",
    "for tool, color in zip(tool_list, color_list):\n",
    "    line_cov, block_cov = [0.0], [0.0]\n",
    "    output_file = tool+\".txt\"\n",
    "    # print(\"drawing \"+output_file)\n",
    "    with open(output_folder+output_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        block_cov.append(float(line.split(\" \")[1]))\n",
    "        line_cov.append(float(line.split(\" \")[2]))\n",
    "    line_cov_list.append(line_cov)\n",
    "    block_cov_list.append(block_cov)\n",
    "plt.figure(figsize=(6, 4))\n",
    "for line_cov, tool, color in zip(line_cov_list, tool_list, color_list):\n",
    "    draw_one_line(line_cov, tool, color)\n",
    "plt.legend(fontsize='small')\n",
    "plt.xticks(np.arange(0, 25, 1))\n",
    "plt.yticks(np.arange(0, 60, 5))\n",
    "plt.margins(x=0, y=0)\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "plt.figure(figsize=(6, 4))\n",
    "for block_cov, tool, color in zip(block_cov_list, tool_list, color_list):\n",
    "    draw_one_line(block_cov, tool, color)\n",
    "plt.legend(fontsize='small')\n",
    "plt.xticks(np.arange(0, 25, 1))\n",
    "plt.yticks(np.arange(0, 45, 5))\n",
    "plt.margins(x=0, y=0)\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "regex = r\"can be detected by (.*)\"\n",
    "lang_results, diff_results = {}, {}\n",
    "lang_dir = \"../data/experiment/anomalies-lang/\"\n",
    "for f in os.listdir(lang_dir):\n",
    "    with open(lang_dir+f) as fi:\n",
    "        first_line = fi.readline()\n",
    "    # print(\"first_line:\"+first_line)\n",
    "    match = re.search(regex, first_line)\n",
    "    tool = match.group(1)\n",
    "    if tool in lang_results:\n",
    "        lang_results[tool] += 1\n",
    "    else:\n",
    "        lang_results[tool] = 1\n",
    "print(tabulate(lang_results.items(), headers=[\"Tool\", \"#Anomalies via language-level test\"]))\n",
    "print(\"\\n\")\n",
    "abl_dir = \"../data/experiment/anomalies-diff/\"\n",
    "for f in os.listdir(abl_dir):\n",
    "    with open(abl_dir+f) as fi:\n",
    "        first_line = fi.readline()\n",
    "    match = re.search(regex, first_line)\n",
    "    tool = match.group(1)\n",
    "    if tool in diff_results:\n",
    "        diff_results[tool] += 1\n",
    "    else:\n",
    "        diff_results[tool] = 1\n",
    "print(tabulate(diff_results.items(), headers=[\"Tool\", \"#Anomalies via differential testing\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for RQ3\n",
    "\n",
    "The Upbeat components all positively contribute to the bugexposing capability of the framework. Run the following two cells to observe the ablation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abl_results = {}\n",
    "abl_dir = \"../data/experiment/ablation-study/\"\n",
    "for f in os.listdir(abl_dir):\n",
    "    with open(abl_dir+f) as fi:\n",
    "        first_line = fi.readline()\n",
    "    match = re.search(regex, first_line)\n",
    "    tool = match.group(1)\n",
    "    if tool in abl_results:\n",
    "        abl_results[tool] += 1\n",
    "    else:\n",
    "        abl_results[tool] = 1\n",
    "print(tabulate(abl_results.items(), headers=[\"Tool\", \"#Bugs\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for RQ4\n",
    "\n",
    "Upbeat is capable of extracting the majority of constraints from both source code and API documents with high accuracy. Run the following two cells to observe the extraction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def get_rate(num1: int, num2: int):\n",
    "    if num2 == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return num1 / num2\n",
    "\n",
    "def convert_to_percent(n):\n",
    "    n = round(n, 2)\n",
    "    # print(\"n:\",n)\n",
    "    return \"%.0f%%\" % (n * 100)\n",
    "\n",
    "def calculate(d: dict):\n",
    "    classical_id, classical_ex, quantum_id, quantum_ex = 0.0, 0.0, 0.0, 0.0\n",
    "    classical_id_total, classical_ex_total, quantum_id_total, quantum_ex_total = 0, 0, 0, 0\n",
    "    for namespace, properties in d.items():\n",
    "        classical_id += get_rate(properties[\"classical-identified\"], properties[\"classical-id-total\"])\n",
    "        classical_ex += get_rate(properties[\"classical-extracted\"], properties[\"classical-ex-total\"])\n",
    "        quantum_id += get_rate(properties[\"quantum-identified\"], properties[\"quantum-id-total\"])        \n",
    "        quantum_ex += get_rate(properties[\"quantum-extracted\"], properties[\"quantum-ex-total\"])\n",
    "        if properties[\"classical-id-total\"] != 0:\n",
    "            classical_id_total += 1\n",
    "        if properties[\"classical-ex-total\"] != 0:\n",
    "            classical_ex_total += 1\n",
    "        if properties[\"quantum-id-total\"] != 0:\n",
    "            quantum_id_total += 1\n",
    "        if properties[\"quantum-ex-total\"] != 0:\n",
    "            quantum_ex_total += 1\n",
    "    # print(\"quantum_extracted:\", quantum_ex)\n",
    "    return convert_to_percent(classical_id / classical_id_total), convert_to_percent(classical_ex / classical_ex_total), \\\n",
    "           convert_to_percent(quantum_id / quantum_id_total), convert_to_percent(quantum_ex / quantum_ex_total)\n",
    "\n",
    "with open(\"../data/experiment/constraint-extraction/source-code.json\") as f1:\n",
    "    code_dict = json.load(f1)\n",
    "code_result = calculate(code_dict)\n",
    "tab = [(\"Source Code\", \"classical\", code_result[0], code_result[1]), (\"\", \"quantum\", code_result[2], code_result[3])]\n",
    "with open(\"../data/experiment/constraint-extraction/api-document.json\") as f2:\n",
    "    doc_dict = json.load(f2)\n",
    "doc_result = calculate(doc_dict)\n",
    "tab.append((\"API Document\", \"classical\", doc_result[0], doc_result[1]))\n",
    "tab.append((\"\", \"quantum\", doc_result[2], doc_result[3]))\n",
    "print(tabulate(tab, headers=[\"Source\", \"Type\", \"Recall\", \"Precision\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
